# Исследование по воспроизведению и улучшению подхода Clio от Anthropic

**Задача:** Извлечение фасетов из диалогов, эмбеддинги, кластеризация, назначение меток кластеров, иерархическая кластеризация — с использованием LLM.

---

## Хронологический лог исследования

### Начальный этап:
1. Для первоначального приближения выбрана модель **DeepSeek-R1-Distill-Qwen-1.5B**. Причина: она единственная помещается в память GPU T4 (fp16 без поддержки fp8) на бесплатном Colab. Модель размера 7B и выше будут тестироваться позже на внутренних серверах.

2. Открытый вопрос: Неясно, используют ли авторы Clio специализированную эмбеддинг-модель или просто LLM для генерации эмбеддингов. Первоначально придерживался второго варианта (LLM), хотя ChatGPT рекомендовал специализированные модели. План: использовать генерацию эмбеддингов от LLM как baseline, позже сравнить со специализированной моделью.

3. Предложение для дополнительного исследования: оценить влияние параметров генерации (`temperature` и `top_p`) на точность итоговой таксономии.

4. Идея для эксперимента: сначала взять стандартный автотокенайзер, а затем обучить/заменить его на русский токенайзер. Также попробовать модель **Qwen-32B** и её русифицированную адаптацию (**ru-adapt Qwen**).

---

## Новые наблюдения и результаты:

### Экспериментальные выводы:

1. Изучив репозиторий OpenClio, обнаружил, что авторы использовали отдельную модель для генерации эмбеддингов. Изначально я использовал обычную LLM, но в будущем лучше перейти на специализированные модели.

2. Перебрал множество моделей для генерации фасетов. Остановился на модели **Qwen-14B R1 Distilled**, показавшей отличные результаты в генерации признаков, суммаризации и формировании тем.

3. Выявлено важное влияние prompt-инжиниринга на качество фасетов. Сначала использовал промпты из репозитория OpenClio, однако там использовалась модель chat completion, что не подходило для Qwen. После корректировки промпта (удаления лишней строки) удалось значительно улучшить качество генерации фасетов.


4. Выявил ошибку на начальном этапе: изначально использовал входные эмбеддинги вместо выходных, не учитывая отсутствие контекстной осведомлённости до прохождения слоёв сети.

5. Решил отказаться от использования **ru-adapt Qwen**, так как улучшения метрик оказались незначительными, а некоторые даже ухудшились. Возможность тестирования оставляю на будущее.

6. Применил 4-битную квантизацию (bitsandbytes), что позволило уместить модели на GPU T4.

7. Решил отказаться от покупки платного Colab или аналогичных сервисов из-за сложностей с переводом денег и высоких комиссий.

8. Новая идея для меток кластеров: вместо наивного суммаризирования через LLM — усреднять эмбеддинги всех summary в кластере и прогонять итоговый вектор через декодер для получения общей метки.

---

## Дополнительные улучшения:
- Добавил визуализацию кластеризации через UMAP.
- Добавил кластеризацию методами DBSCAN и HDBSCAN.

---

## Запланированные и частично реализованные задачи:

На текущий момент выполнено всё, кроме пункта 6:

1. Создать README и лог исследования.
2. Реализовать проверку метрик кластеризации на каждом этапе и оптимизировать гиперпараметры.
3. Учитывать дополнительные фасеты (встраивать их в эмбеддинги или использовать как вспомогательные признаки).
4. Перейти на специализированные модели для генерации sentence embeddings.
5. Провести эксперимент с иерархической кластеризацией двумя способами (используя LLM и scipy.cluster.hierarchy.linkage) и сравнить результаты.
6. Исправить модели в конфигурации (`model_configs`) для эксперимента №2.

---

## Новые идеи и запланированные эксперименты (код уже написан):
- Реализация вычисления метрик кластеризации.
- Использование разных LLM в роли судей и анализ качества извлечения фасетов.
- Перебор и оптимизация гиперпараметров под метрику кластеризации.
- Разработка метрик локальной когерентности и экспериментальная оптимизация гиперпараметров по ним, с последующим сравнением с классическими метриками.
- Контекстно ориентированное назначение меток кластеров (эксперимент 3).
- Самообучающийся (contrastive) эксперимент №4.
- Встраивание дополнительных признаков в эмбеддинги (эксперимент 5).
- Сравнение качества кластеризации при использовании специализированной модели эмбеддингов и «сырого» последнего слоя обычной LLM (эксперимент 6).
